{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95f7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Inicializando Google Earth Engine\n",
    "import numpy as np ## For array handling\n",
    "import pandas as pd ## For dataframes\n",
    "import ee # # Authenticates and initializes Earth Engine\n",
    "import geemap # A dynamic module of Google Earth Engine\n",
    "import fiona # For geopackage file handling \n",
    "from shapely.geometry import shape ## Shapes for geometries\n",
    "import os #To set and modify filepaths\n",
    "import json # For json objects\n",
    "import urllib # For download geopackage files\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal ## Aplying Savistky Golay\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9036638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ee_initialize(): ## Initializing in Google Earth Engine as function\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "    except:\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "ee_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0c665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_url(url): # URL Input verification\n",
    "    \"\"\"Check to see if *url* has a valid protocol.\"\"\"\n",
    "    import urllib \n",
    "    try:\n",
    "        return urllib.parse.urlparse(url).scheme in ('http', 'https') \n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a06f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpkg_to_geojson(in_gpkg, layer= None, out_json=None):\n",
    "    \"\"\"Converts specific layer from geopackage file to GeoJSON.\n",
    "    Args:\n",
    "        in_gpkg (str): File path or URL of geopackage file.\n",
    "        layer (str, optional): Layer name or number of the geopackage file. Defaults first layer as None\n",
    "        out_json (str, optional): File path of the output GeoJSON. Defaults to None.\n",
    "    Returns:\n",
    "        object: The json object representing the geopackage layer.\n",
    "    \"\"\"   \n",
    "    ee_initialize()\n",
    "    try: \n",
    "        import fiona\n",
    "        import json  \n",
    "        if os.path.exists(in_gpkg): # If the path is a filepath      \n",
    "                path_or_bytes = os.path.abspath(in_gpkg)\n",
    "                reader = fiona.open\n",
    "                if out_json is None:  ## Obtaining empty output json\n",
    "                    out_json = os.path.splitext(in_gpkg)[0] + \".json\"\n",
    "                elif os.path.exists(out_json): # If the out_json is duplicated\n",
    "                    out_json = out_json.replace('.json', '_bk.json')  \n",
    "                elif not os.path.exists(os.path.dirname(out_json)): # If the filepath has not been created yet\n",
    "                    os.makedirs(os.path.dirname(out_json))    \n",
    "      \n",
    "                    \n",
    "        elif is_url(in_gpkg): # If the path is a URL                  \n",
    "                path_or_bytes = urllib.request.urlopen(in_gpkg).read()\n",
    "                reader = fiona.BytesCollection            \n",
    "                if out_json is None: # If the ouput name of the json is not specified\n",
    "                    out_json = os.path.split(in_gpkg)[1].split(\".\")[0] + \".json\"\n",
    "                elif os.path.exists(out_json): # If the out_json is duplicated\n",
    "                    out_json = out_json.replace('.json', '_bk.json')    \n",
    "                elif not os.path.exists(os.path.dirname(out_json)): # If the filepath has not been created yet\n",
    "                    os.makedirs(os.path.dirname(out_json))             \n",
    "\n",
    "        buffer=[]         \n",
    "        with reader(path_or_bytes, layer = layer, enabled_drivers=\"GPKG\") as features:\n",
    "            for feature in features: #Reading each feature of geopackage we obtain a dict keys for json\n",
    "                    ids = feature[\"id\"]\n",
    "                    atr = feature[\"properties\"]\n",
    "                    geom = feature[\"geometry\"]\n",
    "                    buffer.append(dict(type=\"Feature\", id = ids, geometry=geom, properties=atr)) \n",
    "\n",
    "        with open(out_json, \"w\") as geojson: \n",
    "            geojson.write(json.dumps({\"type\": \"FeatureCollection\", #Writing in a json our buffer list\n",
    "                                 \"features\":buffer}, indent=2))\n",
    "            geojson.close()          \n",
    "        with open(out_json) as f:\n",
    "             json_data = json.load(f) #Reading a full json and return it as result\n",
    "       \n",
    "        return json_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23d38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi(in_dir):\n",
    "    with fiona.open(in_dir, \"r\", enabled_drivers=\"GPKG\") as source:\n",
    "        for f in source:\n",
    "            geom = shape(f['geometry']).bounds\n",
    "        return [[geom[0], geom[3]],\n",
    "                        [geom[2], geom[3]], \n",
    "                        [geom[2],geom[1]], \n",
    "                        [geom[0],geom[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b3e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpkg_to_ee(in_gpkg, layer=None):\n",
    "    \"\"\"Converts specific layer from geopackage file to  Earth Engine object.\n",
    "    Args:\n",
    "        in_gpkg (str): File path or URL of geopackage file.\n",
    "        layer (str, optional): Layer name or number of the geopackage. Defaults first layer as None\n",
    "        \n",
    "    Returns:\n",
    "        object: Earth Engine objects representing the geopackage layer.\n",
    "    \"\"\"\n",
    "    ee_initialize()\n",
    "    try:\n",
    "        json_data = gpkg_to_geojson(in_gpkg, layer= layer) ## Converting geopackage file to geojson\n",
    "        ee_object  = geemap.geojson_to_ee(json_data) ## Converting geojson to ee object\n",
    "        return ee_object\n",
    "    except Exception as e:\n",
    "        print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##  Descargando coleccion de imagenes MODIS13Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d63430",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector data from filepath\n",
    "workspace = r\"/home/jairflores/Documentos/UNMSM/Fires_Project/AnalisOcurrenIncendiosR/Materiales\"\n",
    "geegpkg = os.path.join(workspace,\"Cutervo.gpkg\")\n",
    "\n",
    "## Creating a ee.FeatureCollection\n",
    "cajamarca_ee= gpkg_to_ee(geegpkg)\n",
    "roi = roi(geegpkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abaa2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map= geemap.Map(center=[-12,-75],zoom=5)\n",
    "Map.add_basemap('SATELLITE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e30a317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NDVI',\n",
       " 'EVI',\n",
       " 'DetailedQA',\n",
       " 'sur_refl_b01',\n",
       " 'sur_refl_b02',\n",
       " 'sur_refl_b03',\n",
       " 'sur_refl_b07',\n",
       " 'ViewZenith',\n",
       " 'SolarZenith',\n",
       " 'RelativeAzimuth',\n",
       " 'DayOfYear',\n",
       " 'SummaryQA']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee.ImageCollection(\"MODIS/006/MOD13Q1\").aggregate_array('system:band_names').getInfo()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e6b556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizar(decimal):\n",
    "    binario = ''\n",
    "    while decimal // 2 != 0:\n",
    "        binario = str(decimal % 2) + binario\n",
    "        decimal = decimal // 2\n",
    "    return \"0\"*(16-(len(binario)+1))+ str(decimal) + binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d93495cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data =[]\n",
    "for i in list(range(1,65536)):\n",
    "           bin_data.append(binarizar(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398ab843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>decimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000000000001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000000000000010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000000000000011</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000000000000100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000000000101</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65530</th>\n",
       "      <td>1111111111111011</td>\n",
       "      <td>65531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65531</th>\n",
       "      <td>1111111111111100</td>\n",
       "      <td>65532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65532</th>\n",
       "      <td>1111111111111101</td>\n",
       "      <td>65533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65533</th>\n",
       "      <td>1111111111111110</td>\n",
       "      <td>65534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65534</th>\n",
       "      <td>1111111111111111</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bin  decimal\n",
       "0      0000000000000001        1\n",
       "1      0000000000000010        2\n",
       "2      0000000000000011        3\n",
       "3      0000000000000100        4\n",
       "4      0000000000000101        5\n",
       "...                 ...      ...\n",
       "65530  1111111111111011    65531\n",
       "65531  1111111111111100    65532\n",
       "65532  1111111111111101    65533\n",
       "65533  1111111111111110    65534\n",
       "65534  1111111111111111    65535\n",
       "\n",
       "[65535 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'bin': bin_data, 'decimal': list(range(1,65536))}\n",
    "data_frame = pd.DataFrame(data=d)\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbf49954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>decimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000000000001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000000000000010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000000000000011</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000000000000100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000000000101</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000000000000110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bin  decimal\n",
       "0  0000000000000001        1\n",
       "1  0000000000000010        2\n",
       "2  0000000000000011        3\n",
       "3  0000000000000100        4\n",
       "4  0000000000000101        5\n",
       "5  0000000000000110        6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bindf = data_frame[data_frame['bin'].apply(lambda x:\n",
    "                                                 x[2:5] == \"011\" or x[2:5] == \"000\" or  x[2:5] == \"100\" \n",
    "                                                 or x[2:5] == \"110\"  or  x[2:5] == \"111\" or  x[1] == \"1\" \n",
    "                                                 or  x[8:9] == \"00\" or x[14:15] == \"11\" or  x[14:15] == \"10\")]\n",
    "data_bindf.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84675a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = ee.Geometry.Polygon(roi, None, False)\n",
    "def scale_factor(image):\n",
    "# scale factor for the MODIS MOD13Q1 product\n",
    "    return image.multiply(0.0001).copyProperties(image, ['system:time_start','system:time_end'])\n",
    "def clipped(image):\n",
    "    return image.clip(aoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0396f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_dataset= ee.ImageCollection(\"MODIS/006/MOD13Q1\").select('NDVI')\\\n",
    "                                 .filter(ee.Filter.date('2000-01-01', '2018-12-31'))\\\n",
    "                                 .map(scale_factor)\n",
    "qa_dataset = ee.ImageCollection(\"MODIS/006/MOD13Q1\").select('DetailedQA')\\\n",
    "                                 .filter(ee.Filter.date('2000-01-01', '2018-12-31'))\n",
    "count = int(ndvi_dataset.size().getInfo())\n",
    "ndvi_images = ndvi_dataset.toList(count)  \n",
    "qa_images = qa_dataset.toList(count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b89d8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeRaster(arr,roi, out_dir):\n",
    "        new_dataset = rio.open(out_dir, 'w', driver='GTiff',\n",
    "                                    height = arr.shape[0], width = arr.shape[1],\n",
    "                                    count=1, dtype=str(arr.dtype),\n",
    "                                    crs='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs ',\n",
    "                                    transform=rio.transform.from_bounds(roi[0][0], roi[2][1],roi[2][0], roi[0][1], arr.shape[1], arr.shape[0]))\n",
    "        new_dataset.write(arr, 1)\n",
    "        new_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bab52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, count):\n",
    "        ## Obteniendo array a partir del Google Earth Engine\n",
    "        ndvi_array=np.array(ee.Image(ndvi_images.get(i))\\\n",
    "                                               .sampleRectangle(region=aoi, defaultValue=-2)\\\n",
    "                                               .get(\"NDVI\").getInfo())\n",
    "        qa_array = np.array(ee.Image(qa_images.get(i))\\\n",
    "                                              .sampleRectangle(region=aoi, defaultValue=0)\\\n",
    "                                              .get(\"DetailedQA\").getInfo())\n",
    "        \n",
    "        ##  Cambiar los valores por defecto a NaN values\n",
    "        ndvi_arr= np.where(ndvi_array==-2,np.nan,ndvi_array)\n",
    "        qa_arr = np.where(ndvi_array== 0,np.nan,qa_array)\n",
    "        \n",
    "        ##  Filtrando el NDVI sin contar los pixeles malos\n",
    "        mask = np.isin(qa_arr, np.array(data_bindf.decimal))\n",
    "        qa_arr[mask] = np.nan\n",
    "        qa_arr[~mask] = 1\n",
    "        ndvi_filter = ndvi_arr*qa_arr\n",
    "        \n",
    "        ## Guardandolo como raster\n",
    "        start = ee.Date(ee.Image(ndvi_images.get(i)).get(\"system:time_start\")).format('YYYY-MM-dd').getInfo() \n",
    "        end = ee.Date(  ee.Image(ndvi_images.get(i)).get(\"system:time_end\")).format('YYYY-MM-dd').getInfo()\n",
    "        filename= \"MOD13Q1_NDVI_filter_250m_16days\" + \"_\" + \"{}\".format(start) +\"_\" +\"{}\".format(end) + \".tif\"\n",
    "        filepath = \"/home/jairflores/Documentos/UNMSM/Teledeteccion/MOD13Q1/NDVI/Filtrado\"\n",
    "        out_dir = os.path.join(filepath,filename)\n",
    "        writeRaster(ndvi_filter,roi,out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9fad89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "def rescaling(in_dir,out_dir, scale):\n",
    "    \n",
    "        with rasterio.open(in_dir) as dataset:\n",
    "            \n",
    "            # resample data to target shape\n",
    "            data =dataset.read( \n",
    "                out_shape=(\n",
    "                    dataset.count,\n",
    "                    int(dataset.height * scale),\n",
    "                    int(dataset.width * scale)\n",
    "                ),\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "\n",
    "            # scale image transform\n",
    "            transform = dataset.transform * dataset.transform.scale(\n",
    "                (dataset.width / data.shape[-1]),\n",
    "                (dataset.height / data.shape[-2])\n",
    "            )\n",
    "          \n",
    "        new_dataset = rio.open(out_dir, 'w', driver='GTiff',\n",
    "                                    height = int(dataset.height * scale) , width =  int(dataset.width * scale),\n",
    "                                    count=1, dtype=str(data.dtype),\n",
    "                                    crs='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs ',\n",
    "                                    transform = dataset.transform * dataset.transform.scale(\n",
    "                                    (dataset.width / data.shape[-1]),\n",
    "                                    (dataset.height / data.shape[-2]) ))\n",
    "        new_dataset.write(data)\n",
    "        new_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3febe6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/home/jairflores/Documentos/UNMSM/Teledeteccion/MOD13Q1/NDVI/Filtrado\"\n",
    "filepath_res = \"/home/jairflores/Documentos/UNMSM/Teledeteccion/MOD13Q1/NDVI/Resampleado\"\n",
    "for t in os.listdir(filepath):\n",
    "        filename= \"MOD13Q1_NDVI_resamp_5km_16days\" + \"_\" + \"{}\".format(t.split(\"_\")[5]) +\"_\" +\"{}\".format(t.split(\"_\")[6])\n",
    "        out_dir = os.path.join(filepath_res,filename)\n",
    "        rescaling(os.path.join(filepath, t),out_dir, scale=1/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e62a3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_index(index):\n",
    "    fixed = []\n",
    "    for a in range(0,len(index)):\n",
    "        mean = np.nanmean(index,axis=0)\n",
    "        fixed.append(np.where(np.isnan(index[a]),mean,index[a]))\n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0c79002",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[]\n",
    "date = []\n",
    "for t in os.listdir(filepath_res):\n",
    "        with rio.open(os.path.join(filepath_res,t)) as src:\n",
    "                    index.append(src.read(1))        \n",
    "                    transform_res = src.transform\n",
    "                    date.append(t.split(\"_\")[5])\n",
    "ind_ = fixed_index(index)                  \n",
    "# Fill NA index data\n",
    "# Dictionary\n",
    "data = {\"Date\":date,\"Index\":ind_}\n",
    "# Data frame\n",
    "df = pd.DataFrame(data,columns = [\"Date\",\"Index\"])\n",
    "# Converting to date time\n",
    "df[\"Date\"] =pd.to_datetime(df[\"Date\"], format='%Y-%m-%d', errors='coerce')\n",
    "df.sort_values(by=\"Date\", key=pd.to_datetime, inplace=True)\n",
    "df\n",
    "# Interpolate missing data in time series\n",
    "df[\"Index\"] = pd.Series(df[\"Index\"]).interpolate(limit = len(date))\n",
    "\n",
    "## Interpolando los valores a través del filtro Savistky Golaydf\n",
    "df[\"SavGol\"]=df[\"Index\"].apply(lambda x: signal.savgol_filter(x,7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "90798cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_savgol = \"/home/jairflores/Documentos/UNMSM/Teledeteccion/MOD13Q1/NDVI/SavGol\"\n",
    "for i in range(0,len(df[\"SavGol\"])):\n",
    "    filename= \"MOD13Q1_NDVI_SavGol_5km_16days\" + \"_\" + \"{}\".format(str(df[\"Date\"][i]).split(\" \")[0]) + \".tif\"\n",
    "    out_dir = os.path.join(filepath_savgol,filename)\n",
    "    arr=df[\"SavGol\"][i]\n",
    "    new_dataset = rio.open(out_dir, 'w', driver='GTiff',\n",
    "                            height = arr.shape[0], width = arr.shape[1],\n",
    "                            count=1, dtype=str(arr.dtype),\n",
    "                            crs='+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs ',\n",
    "                            transform= transform_res)\n",
    "    new_dataset.write(arr, 1)\n",
    "    new_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3af670fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_savgol = \"/home/jairflores/Documentos/UNMSM/Teledeteccion/MOD13Q1/NDVI/SavGol\"\n",
    "tif_list=[]\n",
    "for i in os.listdir(filepath_savgol):\n",
    "       tif_list.append(os.path.join(filepath_savgol,i))\n",
    "# Read metadata of first file\n",
    "with rasterio.open(tif_list[0]) as src0:\n",
    "    meta = src0.meta\n",
    "# Update meta to reflect the number of layers\n",
    "meta.update(count = len(tif_list))\n",
    "# Read each layer and write it to stack\n",
    "with rasterio.open(os.path.join(filepath_savgol,'stack.tif'), 'w', **meta) as dst:\n",
    "    for id, layer in enumerate(tif_list, start=1):\n",
    "        with rasterio.open(layer) as src1:\n",
    "            dst.write_band(id, src1.read(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b443787",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_month = df.groupby(by=\"month\")[\"SavGol\"].apply(np.mean)\n",
    "ndvi_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fb8d2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = pd.DatetimeIndex(df['Date']).month\n",
    "df.to_csv(os.path.join(filepath_savgol,\"data_SavGol.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
